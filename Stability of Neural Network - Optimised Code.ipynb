{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy as sc\n",
    "from scipy.stats import norm\n",
    "from scipy.special import roots_hermite\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.optimizers as opt\n",
    "from keras.constraints import Constraint\n",
    "import sobol_seq\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras import backend as keras_backend\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "num_cores = 32\n",
    "num_CPU = 1\n",
    "num_GPU = 0\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores, inter_op_parallelism_threads=num_cores,\n",
    "                        allow_soft_placement=True, device_count={'CPU': num_CPU, 'GPU': num_GPU})\n",
    "session = tf.Session(config=config)\n",
    "keras_backend.set_session(session)\n",
    "\n",
    "################################################################\n",
    "# Parameters to control the neural network - rest are fixed ###\n",
    "###############################################################\n",
    "\n",
    "#No.of.derivative contracts used for static hedging\n",
    "no_of_options=5\n",
    "\n",
    "#Runs\n",
    "no_of_runs = 4\n",
    "\n",
    "#No of paths\n",
    "no_of_paths = 5000\n",
    "no_of_paths_test = 5000\n",
    "\n",
    "################\n",
    "# Type of Model#\n",
    "###############\n",
    "\n",
    "#Can Take following values: 1. \"UnConstrained Neural Network\", 2. \"Constrained Neural Network\"\n",
    "model_type = \"UnConstrained Neural Network\"\n",
    "\n",
    "#Type of Bias Initialisation: 1. \"normal0.1\", 2. \"gauss adjusted strikes\", \n",
    "#3.\"opp sign of weight uniform0.5\", 4.\"default\", 5. \"normal0.1_seed_fix\"\n",
    "hidden_bias_init = \"default\"\n",
    "\n",
    "#Type of hidden weight initialisation: 1. \"uniform0.5\", 2. \"ones constraint\" \n",
    "hidden_weight_init = \"uniform0.5\"\n",
    "\n",
    "#Outer Weights: 1. \"random uniform\", 2. \"equal weights\", 3.\"high centred\", \n",
    "#               4.\"random uniform non-negative\"\n",
    "outer_weight_init = \"random uniform\"\n",
    "\n",
    "#Outer Bias: 1. \"default\", 2.\"no bias\", 3. \"non negative\"\n",
    "outer_bias_init = \"default\"\n",
    "\n",
    "# file_ident = \"constr_normal\"\n",
    "# file_ident = \"unconstr_opps\"\n",
    "file_ident = \"unconstr\"\n",
    "# file_ident = \"constr_nomal_fixSeed\"\n",
    "\n",
    "# constrained = (\"normal0.1, ones constraint, equal_weights\"), \n",
    "#               (\"gauss adjusted strikes\", ones_consraint, equal weights), \n",
    "#                (\"gauss adjusted strikes, ones_constraint, gauss weights\" -> not now)\n",
    "#Unconstrained = (\"UnConstrained Neural Network, default, uniform0.5, random uniform\"), \n",
    "#                (\"UnConstrained Neural Network, \"opp sign of weight uniform0.5\", uniform0.5, random uniform\"),\n",
    "#                (UnConstrained Neural Network, \"opp sign of weight uniform0.5\", uniform0.5, same sign and init as inner weight -> not now\")\n",
    "#Buy call sell puts\n",
    "# constrained = (\"normal0.1, ones constraint, equal_weights\"), \n",
    "#               (\"gauss adjusted strikes\", ones_consraint, equal weights), \n",
    "#                (\"gauss adjusted strikes, ones_constraint, gauss weights\" -> not now)\n",
    "#Unconstrained = (\"UnConstrained Neural Network, default, uniform0.5, random uniform -> only available\"), \n",
    "#                (\"UnConstrained Neural Network, \"opp sign of weight uniform0.5\", uniform0.5, random uniform\"),\n",
    "#                (UnConstrained Neural Network, \"opp sign of weight uniform0.5\", uniform0.5, same sign and init as inner weight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the option to be hedged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramater based on Carr's Static Hedge of Standard options\n",
    "#Current Stock Price\n",
    "S0=100\n",
    "\n",
    "#Risk Free Interest Rate\n",
    "r=0.06 \n",
    "\n",
    "#Continuos Divident rate\n",
    "delta=0.02\n",
    "\n",
    "#Volatility\n",
    "sigma=0.27 \n",
    "\n",
    "# Time to maturity for the shorter term options = 0.25 yrs \n",
    "t=0.25  \n",
    "\n",
    "# Time to maturity for the target options = 1 yr\n",
    "T=1\n",
    "\n",
    "# Size of each step = 0.01\n",
    "dt=0.01\n",
    "\n",
    "# The call was struck at the money on 11/08/2020\n",
    "K=100 \n",
    "\n",
    "# No. of sim time points\n",
    "sim_grid_points = int(t/dt)\n",
    "\n",
    "#No. of. time points\n",
    "sim_points = [dt * i for i in range(1, sim_grid_points + 1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Simulated Stocks dataframe: for both Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Simulation of Stocks: Training and Testing #\n",
    "##############################################\n",
    "\n",
    "# #  Simulated stock prices for Training\n",
    "# df_sim_stocks=pd.DataFrame(np.zeros(no_of_paths * (sim_grid_points + 1)).reshape(sim_grid_points + 1, no_of_paths))\n",
    "\n",
    "# for path in np.arange(0,no_of_paths):\n",
    "#     np.random.seed(path)\n",
    "#     for i in np.arange(1,sim_grid_points + 1):\n",
    "#             df_sim_stocks.loc[0,path]=S0\n",
    "#             df_sim_stocks.loc[i,path]=df_sim_stocks.loc[i-1,path] + (r-delta)*df_sim_stocks.loc[i-1,path]*dt + sigma*df_sim_stocks.loc[i-1,path]*np.sqrt(dt)*np.random.randn()\n",
    "\n",
    "# #Simulated Stocks for Testing            \n",
    "# df_sim_stocks_test=pd.DataFrame(np.zeros(no_of_paths_test * (sim_grid_points + 1)).reshape(sim_grid_points + 1, no_of_paths_test))\n",
    "\n",
    "# for path in np.arange(0,no_of_paths_test):\n",
    "#     np.random.seed(path+no_of_paths)\n",
    "#     for i in np.arange(1,sim_grid_points + 1):\n",
    "#             df_sim_stocks_test.loc[0,path]=S0\n",
    "#             df_sim_stocks_test.loc[i,path]=df_sim_stocks_test.loc[i-1,path] + (r-delta)*df_sim_stocks_test.loc[i-1,path]*dt + sigma*df_sim_stocks_test.loc[i-1,path]*np.sqrt(dt)*np.random.randn()\n",
    "\n",
    "# # Load the simulated stock dataframes to csv\n",
    "# df_sim_stocks.to_csv('Stability Analysis - Outputs/Dataframes Optimized/Stock Simulations/df_sim_stocks_sim' + str(no_of_paths) + '.csv')\n",
    "# df_sim_stocks_test.to_csv('Stability Analysis - Outputs/Dataframes Optimized/Stock Simulations/df_sim_stocks_test_sim' + str(no_of_paths_test) + '.csv')\n",
    "\n",
    "#Load the simulated stock dataframes back from csv - to avoid re-running of simualtion\n",
    "df_sim_stocks = pd.read_csv('Stability Analysis - Outputs/Dataframes Optimized/Stock Simulations/df_sim_stocks_sim' + str(no_of_paths) + '.csv', index_col=0)\n",
    "df_sim_stocks_test = pd.read_csv('Stability Analysis - Outputs/Dataframes Optimized/Stock Simulations/df_sim_stocks_test_sim' + str(no_of_paths_test) + '.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Black-Schole Option price of the option to be hedged at all simulated levels of stocks - for both Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical PV:  12.353846694091985\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Generate Blacl-Scholes price for stock simulations #\n",
    "######################################################\n",
    "\n",
    "# Black-Scholes function\n",
    "\n",
    "def d1(S0, r, delta, t0, t, k, sigma):\n",
    "    return 1/(sigma*np.sqrt(t-t0)) * (np.log(S0/k) + (r-delta+(sigma**2)/2)*(t-t0))\n",
    "\n",
    "def d2(S0, r, delta, t0, t, k, sigma):\n",
    "    return 1/(sigma*np.sqrt(t-t0)) * (np.log(S0/k) + (r-delta-(sigma**2)/2)*(t-t0))\n",
    "\n",
    "def BSMcall(S0, r, delta, t0, t, k, sigma):\n",
    "    return S0*np.exp(-delta*(t-t0))*norm.cdf(d1(S0, r, delta, t0, t, k, sigma)) - k*np.exp(-r*(t-t0))*norm.cdf(d2(S0, r, delta, t0, t, k, sigma))\n",
    "\n",
    "def BSMPut(S0, r, delta, t0, t, k, sigma):\n",
    "    return k*np.exp(-r*(t-t0))*norm.cdf(-d2(S0, r, delta, t0, t, k, sigma)) - S0*np.exp(-delta*(t-t0))*norm.cdf(-d1(S0, r, delta, t0, t, k, sigma))\n",
    "\n",
    "def fwdValue(S0, r, delta, t0, t, k):\n",
    "    return S0*np.exp(-delta*(t-t0)) - k*np.exp(-r*(t-t0))\n",
    "\n",
    "def depositPV(t0, t, p):\n",
    "    return p*np.exp(-r*(t-t0))\n",
    "    \n",
    "#Generate Black-Scholes price for all paths and time grid points - Training Sample\n",
    "# df_bs_price = pd.DataFrame(np.zeros(no_of_paths * (sim_grid_points + 1)).reshape(sim_grid_points + 1, no_of_paths),index=df_sim_stocks.index)\n",
    "# for grid in np.arange(0, sim_grid_points+1):\n",
    "#     df_bs_price.iloc[grid, :] = BSMcall(((df_sim_stocks.iloc[grid,:]).to_numpy()).reshape(1,-1) , r, delta, grid*dt, T, K, sigma)\n",
    "    \n",
    "#Generate Black-Scholes price for all paths and time grid points - Testin Sample\n",
    "# df_bs_price_test = pd.DataFrame(np.zeros(no_of_paths * (sim_grid_points + 1)).reshape(sim_grid_points + 1, no_of_paths),index=df_sim_stocks_test.index)\n",
    "# for grid in np.arange(0, sim_grid_points+1):\n",
    "#     df_bs_price_test.iloc[grid, :] = BSMcall(((df_sim_stocks_test.iloc[grid,:]).to_numpy()).reshape(1,-1) , r, delta, grid*dt, T, K, sigma)\n",
    "\n",
    "# Load the simulated stock dataframes to csv\n",
    "# df_bs_price.to_csv('Stability Analysis - Outputs/Dataframes Optimized/df_bs_price_sim' + str(no_of_paths) + '.csv')\n",
    "# df_bs_price_test.to_csv('Stability Analysis - Outputs/Dataframes Optimized/df_bs_price_test_sim' + str(no_of_paths_test) + '.csv')\n",
    "\n",
    "#Load BS Price dataframes from geenrated csv files\n",
    "df_bs_price = pd.read_csv('Stability Analysis - Outputs/Dataframes Optimized/df_bs_price_sim' + str(no_of_paths) + '.csv', index_col=0)\n",
    "df_bs_price_test = pd.read_csv('Stability Analysis - Outputs/Dataframes Optimized/df_bs_price_test_sim' + str(no_of_paths_test) + '.csv', index_col=0)\n",
    "\n",
    "print(\"Theoretical PV: \", df_bs_price.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carr Static Hedge Section\n",
    "\n",
    "**Generate static hedge portfolio and value the portfolio at time 0 and at simulated levels of stock at termination of short term options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hermitetuple(no_of_options):\n",
    "    return pd.DataFrame(roots_hermite(no_of_options)).transpose()\n",
    "\n",
    "def findStrikes(x):\n",
    "    return K*np.exp(x*sigma*np.sqrt(2*(T-t))+(delta-r-(sigma**2)/2)*(T-t))\n",
    "\n",
    "def findWeights(x):\n",
    "    return (np.exp(-delta*(T-t))/np.sqrt(np.pi))*x   \n",
    "\n",
    "def portfolioStrikes(no_of_options):\n",
    "    return pd.Series(Hermitetuple(no_of_options)[0].apply(findStrikes))\n",
    "\n",
    "def portfolioWeights(no_of_options):\n",
    "    return pd.Series(Hermitetuple(no_of_options)[1].apply(findWeights))\n",
    "\n",
    "stock_vec = df_sim_stocks_test.iloc[-1, :] \n",
    "stock_vec = (stock_vec.to_numpy()).reshape(-1,1)\n",
    "\n",
    "no_of_options_list = [5, 9, 15, 21]\n",
    "\n",
    "def find_carr_static_hedge_error(no_of_options_list, stock_vec, df_bs_price_test, no_of_paths_test):\n",
    "    df_carr_pv_rmse = df_nn_hedge_params = pd.DataFrame(columns=['Options Count','Carr PV', 'Carr RMSE'],  \n",
    "                                                        index=[i for i in range(0, len(no_of_options_list))])\n",
    "    df_carr_hedge_error = pd.DataFrame(columns=['Options Count:' + str(no_of_opt) for no_of_opt in no_of_options_list], \n",
    "                                       index=[i for i in range(0, no_of_paths_test)])\n",
    "    \n",
    "    i = 0\n",
    "    for no_of_opt in no_of_options_list:\n",
    "        wts = (portfolioWeights(no_of_options=no_of_opt).to_numpy()).reshape(1,-1)\n",
    "        strks = (portfolioStrikes(no_of_options=no_of_opt).to_numpy()).reshape(1,-1)\n",
    "        static_hedge_carr = np.sum(wts*(np.maximum(stock_vec-strks,0)),axis=1)\n",
    "        static_hedge_carr_error = static_hedge_carr - df_bs_price_test.iloc[-1, :].to_numpy()\n",
    "        static_hedge_carr_rmse = np.sqrt(np.mean(np.square(static_hedge_carr_error)))\n",
    "        pvt0_carr = np.sum(wts*BSMcall(S0, r, delta, 0, t, strks, sigma))\n",
    "        df_carr_pv_rmse.loc[i, ['Options Count','Carr PV', 'Carr RMSE']] = np.array([no_of_opt, pvt0_carr, static_hedge_carr_rmse]).reshape(1,-1)\n",
    "        i=i+1\n",
    "        df_carr_hedge_error.loc[:, 'Options Count:' + str(no_of_opt)] = static_hedge_carr_error.reshape(-1,1)\n",
    "    df_carr_pv_rmse.to_csv('Stability Analysis - Outputs/Dataframes Optimized/df_carr_pv_rmse_sim' + str(no_of_paths) + '.csv')\n",
    "    df_carr_hedge_error.to_csv('Stability Analysis - Outputs/Dataframes Optimized/df_carr_hedge_error_sim' + str(no_of_paths) + '.csv')\n",
    "    \n",
    "    return None\n",
    "\n",
    "find_carr_static_hedge_error(no_of_options_list, stock_vec, df_bs_price_test, no_of_paths_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      21.322668\n",
      "1      28.057316\n",
      "2      35.397692\n",
      "3      43.761607\n",
      "4      53.466946\n",
      "5      64.854138\n",
      "6      78.333460\n",
      "7      94.427532\n",
      "8     113.828226\n",
      "9     137.486352\n",
      "10    166.767687\n",
      "11    203.753005\n",
      "12    251.896617\n",
      "13    317.798002\n",
      "14    418.172753\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "no_of_options = 15\n",
    "print(portfolioStrikes(no_of_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Implementation of Neural Network\n",
    "\n",
    "The static hedging is implemented using a neural network with one hidden layer and no constraints on the weights. The expectation of hidden layer nodes lead to four cases listed below - explained with hidden layer of four different possibilites of weights and nodes combination (in terms of sign): <br>\n",
    "\n",
    "\n",
    "$Neural \\ output =  w_{11}^{1}(w_{11}^{0} S  + k_1)^{+} + w_{21}^{1}(w_{12}^{0} S  + k_2)^{+} + w_{31}^{1}(w_{13}^{0} S  + k_3)^{+} + w_{40}^{1}(w_{14}^{0} S  + k_4)^{+} + K_{0}^{Out}$, <br>\n",
    "\n",
    "where, <br>\n",
    "$w_{ij}^{k}$ is the weight from $i^{th}$ node in layer $k$ to $j^{th}$ node in layer $k+1$, <br>\n",
    "$w_{11}^{0}$ & $w_{12}^{0}$ are considered positve while, $w_{13}^{0}$ & $w_{14}^{0}$ are considered negative, <br>\n",
    "$k_1, k_2, k_4, k_5$ are bias of hidden nodes s.t. $k_1$ and $k_3$ are negative while $k_2$ and $k_4$ are positive real numbers, <br>\n",
    "$K_{0}^{Out}$ is the bias in the outer layer, <br>\n",
    "Input layer is 0 layer, Hidden layer is layer 1 and output layer is layer 2, <br>\n",
    "$S = \\frac{S_{t}}{S_{0}}$. <br>\n",
    "\n",
    "Hence, the above equation can be written as, <br>\n",
    "\n",
    "$Neural \\ output =  w_{10}^{1}* |w_{11}^{0}| *(S  - \\frac{|k_1|}{|w_{11}^{0}|})^{+} + w_{20}^{1} * |w_{12}^{0}| * ( S  + \\frac{|k_2|}{|w_{12}^{0}|})^{+} + w_{30}^{1}*|w_{13}^{0}|*(-\\frac{|k_3|}{|w_{13}^{0}|} - S )^{+} + w_{40}^{1}*|w_{14}^{0}|*( \\frac{|k_4|}{|w_{14}^{0}|} - S)^{+}$. <br>\n",
    "\n",
    "Further, We are performing neural network on $\\frac{stock}{stock \\ at \\ valuation \\ time}$. So, we have to multiply the $S_0$ on both sides. Also, we train $\\frac{S_{t}}{S_{0}}$ with BS price divided by $S_{0}$. The valuation time is $t_{0}$ and expiry of short-term options is $t$. <br>\n",
    "\n",
    "So, to get the actual hedge portfolio, we multiply by $S_0$ and then find Expectation discounted to valuation time, which gives the following portfolio: <br>\n",
    "\n",
    "1. vol - volatility of stock at $t_{0}$, <br>\n",
    "\n",
    "2. $ w_{10}^{1}*|w_{11}^{0}| * Call \\ option (Spot=S_{0}, Strike = S_{0}*\\frac{|k_1|}{|w_{11}^{0}|}, (t-t_{0}), vol)$; <br>\n",
    "\n",
    "3. $w_{40}^{1}*|w_{14}^{0}| * Put \\ option (Spot=S_{0}, Strike = S_{0}*\\frac{|k_4|}{|w_{14}^{0}|}, (t-t_{0}), vol)$;\n",
    "<br>\n",
    "\n",
    "4. $w_{20}^{1} * |w_{12}^{0}| * Forward \\ contract(Spot=S_{0}, Strike= - S_{0} * (\\frac{|k_2|}{|w_{12}^{0}|}))$ -> The value of this contract at any time $t^{'}$, s.t. $t_0 < t^{'} < t$, is given by $S_{t^{'}} * e^{-q*(t-t^{'})} + S_{0} * \\frac{|k_2|}{|w_{12}^{0}|} * e^{-r(t-t^{'})}$ or it can be thought forward contract with strike zero and a cash flow or deposit of $S_{0} * (\\frac{|k_2|}{|w_{12}^{0}|}))$, <br>\n",
    "\n",
    "Finally, we have the deposit account mentioned below: <br>\n",
    "\n",
    "5. Casflow of $K_{0}^{Out} * S_{0}$ at time $t$, hence a deposit of $K_{0}^{Out} * S_{0} * e^{-r(t-t_{0})}$ at time $t_{0}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "############# Original Implementation of Neural Network #############\n",
    "#####################################################################\n",
    "\n",
    "class Between(Constraint):\n",
    "    def __init__(self, min_value, max_value):\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "\n",
    "    def __call__(self, w):        \n",
    "        return keras_backend.clip(w, self.min_value, self.max_value)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'min_value': self.min_value,\n",
    "                'max_value': self.max_value}\n",
    "\n",
    "def preTrainNeuralNet(df_bs_price, df_sim_stocks, \n",
    "                      no_of_options, no_of_epochs, batch_size, \n",
    "                      model_type, hidden_bias_init, hidden_weight_init, outer_bias_init):\n",
    "    \n",
    "    s_init = df_sim_stocks.iloc[0,0]\n",
    "        \n",
    "    nnet_model = Sequential()\n",
    "    if (model_type == \"Constrained Neural Network\"):\n",
    "        ones_array = np.array([1 for i in range(0, no_of_options)]).reshape(1,no_of_options)\n",
    "        hidden_kernel_constraint = tf.keras.constraints.MinMaxNorm(min_value=1.0, max_value=1.0, rate=1.0, axis=0)\n",
    "        hidden_layer = Dense(no_of_options, activation='relu', kernel_constraint=hidden_kernel_constraint, \n",
    "                             bias_constraint=Between(-999999, 0), input_dim=1)\n",
    "        hidden_layer.trainable = True\n",
    "        nnet_model.add(hidden_layer)    \n",
    "        \n",
    "        if (hidden_bias_init == \"normal0.1\"):\n",
    "            strikes_init = [np.random.normal(1, 0.1) for i in range(0, no_of_options-1)]\n",
    "            strikes_init.append(1)\n",
    "            strikes_init = -1 * np.array(strikes_init).reshape(-1)\n",
    "            \n",
    "        elif (hidden_bias_init == \"normal0.1_seed_fix\"):   \n",
    "            #If Seed is fixed:\n",
    "            np.random.seed(999)\n",
    "            strikes_init = list(np.random.normal(1,0.1, size=(no_of_options,)))\n",
    "            strikes_init = -1 * np.array(strikes_init).reshape(-1)\n",
    "        \n",
    "        else:\n",
    "            strikes_init = np.array(Hermitetuple(no_of_options)[0] + np.amax(Hermitetuple(no_of_options)[0])).reshape(-1)\n",
    "            strikes_init = strikes_init / np.mean(strikes_init)\n",
    "        \n",
    "        hidden_weights = [ones_array, strikes_init]\n",
    "        nnet_model.layers[0].set_weights(hidden_weights)\n",
    "        outer_initializer = tf.keras.initializers.Constant(value=(1/no_of_options))\n",
    "        output_layer = Dense(1, activation='linear', kernel_initializer=outer_initializer, use_bias=False)\n",
    "        output_layer.trainable = True\n",
    "        nnet_model.add(output_layer)\n",
    "    else: \n",
    "        if (hidden_bias_init == \"opp sign of weight uniform0.5\"):\n",
    "            hidden_layer = Dense(no_of_options, activation='relu', input_dim=1)\n",
    "            hidden_layer.trainable = True\n",
    "            nnet_model.add(hidden_layer)    \n",
    "            strikes_init = np.array(np.random.uniform(low=-0.5, high=0.5, size=no_of_options)).reshape(-1)\n",
    "            inner_wts = -1 * strikes_init.reshape(1, -1)\n",
    "            hidden_weights = [inner_wts, strikes_init]\n",
    "            nnet_model.layers[0].set_weights(hidden_weights)     \n",
    "        else:\n",
    "            nnet_model.add(Dense(no_of_options, activation='relu', \n",
    "                             kernel_initializer=keras.initializers.RandomUniform(minval=-0.5, maxval=0.5,seed=None)\n",
    "                             ))\n",
    "        if (outer_weight_init == \"random uniform non-negative\"):    \n",
    "            nnet_model.add(Dense(1, activation='linear', kernel_initializer='random_uniform', kernel_constraint = tf.keras.constraints.NonNeg()))\n",
    "        else:\n",
    "            nnet_model.add(Dense(1, activation='linear', kernel_initializer='random_uniform'))\n",
    "     \n",
    "    nnet_model.compile(optimizer=opt.Adam(lr=0.001), loss='mean_squared_error')\n",
    "    \n",
    "    stock_vec = np.array(df_sim_stocks.iloc[-1, :]) / s_init\n",
    "    bs_value = np.array(df_bs_price.iloc[-1, :]) / s_init\n",
    "    \n",
    "    X_train = stock_vec.reshape(-1, 1)\n",
    "    Y_train = np.asarray(bs_value).reshape(-1, 1)\n",
    "    \n",
    "    nnet_output = nnet_model.fit(X_train, Y_train, epochs=no_of_epochs, batch_size=batch_size, verbose=0,\n",
    "                                 validation_split=0.3)\n",
    "    return nnet_model\n",
    "    \n",
    "def staticHedgeNeural(df_bs_price, df_sim_stocks, pre_nnet_model_orig, \n",
    "                                  no_of_options, no_of_epochs, batch_size):\n",
    "    \n",
    "    s_init = df_sim_stocks.iloc[0,0]\n",
    "    stock_vec = np.array(df_sim_stocks.iloc[-1, :]) / s_init\n",
    "    bs_value = np.array(df_bs_price.iloc[-1, :]) / s_init\n",
    "\n",
    "    X_train = stock_vec.reshape(-1, 1)\n",
    "    Y_train = bs_value.reshape(-1, 1)\n",
    "\n",
    "    nnet_model = pre_nnet_model_orig\n",
    "    nnet_output = nnet_model.fit(X_train, Y_train, epochs=no_of_epochs, batch_size=batch_size, verbose=0,\n",
    "                                 validation_split=0.3)\n",
    "    \n",
    "    return nnet_model, s_init\n",
    "\n",
    "\n",
    "def identify_positions(wt_list, strike_list):\n",
    "    positions = np.where(np.logical_and(wt_list>0, strike_list<0), \"C\", \n",
    "                        np.where(np.logical_and(wt_list>0, strike_list>=0), \"F\", \n",
    "                                 np.where(np.logical_and(wt_list<0, strike_list>0), \"P\", \"N\")))\n",
    "    \n",
    "    pos = (np.array(np.unique(positions, return_counts=True)).T)\n",
    "    no_of_pos_dict = {\"C\":0 , \"P\":0, \"F\":0 , \"N\":0 }\n",
    "    \n",
    "    for i in range(0, len(pos[:,0])):\n",
    "        no_of_pos_dict[pos[i,0]] = int(pos[i,1])\n",
    "\n",
    "    return no_of_pos_dict[\"C\"], no_of_pos_dict[\"P\"], no_of_pos_dict[\"F\"], no_of_pos_dict[\"N\"], positions\n",
    "\n",
    "def find_instr_params(nn_strikes, inner_wts, outer_wts, outer_bias, positions, s_init):\n",
    "    strikes_array = np.where(positions == \"F\", \n",
    "                            - s_init * np.divide(np.abs(nn_strikes), np.abs(inner_wts)), \n",
    "                            s_init * np.divide(np.abs(nn_strikes), np.abs(inner_wts)))\n",
    "    deposit = outer_bias * s_init\n",
    "    pfl_weights = np.multiply(np.abs(inner_wts), outer_wts)\n",
    "    \n",
    "    return strikes_array, deposit, pfl_weights\n",
    "\n",
    "def static_hedge_value_nn(stock_vec, strike_list, positions, pfl_wts, deposit, \n",
    "                          s_init, r, delta, sigma, t):\n",
    "    strks = strike_list.reshape(1,-1)\n",
    "    non_neg_strks = np.abs(strks)\n",
    "    wts = pfl_wts.reshape(1,-1)\n",
    "    pos = positions.reshape(1,-1)\n",
    "    c_wt =   np.multiply(wts, np.where(pos==\"C\", 1, 0))\n",
    "    p_wt =   np.multiply(wts, np.where(pos==\"P\", 1, 0))\n",
    "    f_wt =   np.multiply(wts, np.where(pos==\"F\", 1, 0))\n",
    "    \n",
    "    stock_vec = stock_vec.reshape(-1,1)\n",
    "    nn_static_hedge_value = np.sum(c_wt*(np.maximum(stock_vec-non_neg_strks,0)) + \n",
    "                             p_wt*(np.maximum(non_neg_strks-stock_vec,0)) + \n",
    "                             f_wt*(stock_vec-strks), axis=1) + deposit\n",
    "    \n",
    "    pvt0_nn = np.sum(c_wt*BSMcall(s_init, r, delta, 0, t, non_neg_strks, sigma) + \n",
    "                     p_wt*BSMcall(s_init, r, delta, 0, t, non_neg_strks, sigma) + \n",
    "                     f_wt*fwdValue(s_init, r, delta, 0, t, strks), axis=1) + deposit * np.exp(-r*t)\n",
    "    \n",
    "    return nn_static_hedge_value, pvt0_nn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Static Hedge using Neural Network\n",
    "\n",
    "def generate_nn_hedge(df_sim_stocks, df_sim_stocks_test, df_bs_price, df_bs_price_test, \n",
    "                      no_of_options, r, delta, sigma, t, \n",
    "                     model_type, hidden_bias_init, hidden_weight_init, outer_bias_init):\n",
    "    batch_size_divisor = 10\n",
    "    no_of_epochs = 100  \n",
    "    batch_size = int(no_of_paths/batch_size_divisor)\n",
    "    pre_nnet_model_orig = preTrainNeuralNet(df_bs_price, df_sim_stocks, no_of_options, no_of_epochs, batch_size, \n",
    "                                                    model_type, hidden_bias_init, hidden_weight_init, outer_bias_init)\n",
    "    no_of_epochs = 1000 \n",
    "    nnet_model_orig, s_init = staticHedgeNeural(df_bs_price, df_sim_stocks, pre_nnet_model_orig, no_of_options, no_of_epochs, batch_size)\n",
    "    \n",
    "    #Neural Network Weights\n",
    "    inner_wts = np.array(nnet_model_orig.layers[0].get_weights()[0]).reshape(-1)\n",
    "    nn_strikes_orig = np.array(nnet_model_orig.layers[0].get_weights()[1]).reshape(-1)\n",
    "    outer_wts = np.array(nnet_model_orig.layers[1].get_weights()[0]).reshape(-1)\n",
    "    if (outer_bias_init == \"no bias\"):\n",
    "        outer_bias = np.array([0]).reshape(-1)\n",
    "    else:\n",
    "        outer_bias = np.array(nnet_model_orig.layers[1].get_weights()[1]).reshape(-1)\n",
    "    \n",
    "    #Genererate Derivative contract equivalents from weights\n",
    "    global no_of_calls, no_of_puts, no_of_fwds, nulls, positions, strike_arry, deposit, pfl_wts\n",
    "    no_of_calls, no_of_puts, no_of_fwds, no_of_nulls, positions = identify_positions(inner_wts, nn_strikes_orig)\n",
    "    strike_array, deposit, pfl_wts = find_instr_params(nn_strikes_orig, inner_wts, outer_wts, outer_bias, positions, s_init)\n",
    "    deposit_list = np.array([deposit for i in range(0, no_of_options)])\n",
    "    params = [strike_array.reshape(no_of_options,1), deposit_list.reshape(no_of_options,1), pfl_wts.reshape(no_of_options,1)]\n",
    "    \n",
    "    #Generate Hedge Values\n",
    "    stock_vec = np.array(df_sim_stocks_test.iloc[-1,:]).reshape(-1)\n",
    "    nn_static_hedge_value, pvt0_nn = static_hedge_value_nn(stock_vec, strike_array, positions, pfl_wts, deposit, \n",
    "                                                           s_init, r, delta, sigma, t)\n",
    "    theor_bs_price = np.array(df_bs_price_test.iloc[-1,:]).reshape(-1)\n",
    "    nn_static_hedge_err = nn_static_hedge_value - theor_bs_price\n",
    "    nn_rmse = np.sqrt(np.mean(np.square(nn_static_hedge_err)))\n",
    "    \n",
    "    return pvt0_nn, nn_rmse, nn_static_hedge_err, [no_of_calls, no_of_puts, no_of_fwds, no_of_nulls], positions, params\n",
    "\n",
    "\n",
    "def load_runs_to_df(df_sim_stocks, df_sim_stocks_test, df_bs_price, df_bs_price_test, \n",
    "                    no_of_options, r, delta, sigma, t, \n",
    "                    model_type, hidden_bias_init, hidden_weight_init, outer_bias_init,\n",
    "                    no_of_runs=4):\n",
    "    df_nn_hedge_pv_instr_nos = pd.DataFrame(columns=['PV', 'NN RMSE', 'Calls Count', 'Puts Count', 'Fwds Count', 'Nulls Count'], \n",
    "                                  index=[i for i in range(1, no_of_runs+1)])\n",
    "    df_nn_hedge_params = pd.DataFrame(columns=['Runs', 'Positions', 'Strike', 'Pfl Wts', 'Deposit'], \n",
    "                                  index=[i for i in range(1, no_of_runs*no_of_options + 1)])\n",
    "    df_nn_hedge_error = pd.DataFrame(columns=['Run' + str(i) for i in range(1, no_of_runs + 1)], \n",
    "                                  index=[i for i in range(1, no_of_paths + 1)])\n",
    "\n",
    "    for run in range(1, no_of_runs+1):\n",
    "        pvt0_nn, nn_rmse, nn_static_hedge_err, instr_nos, positions, params = generate_nn_hedge(df_sim_stocks, df_sim_stocks_test, df_bs_price, df_bs_price_test, \n",
    "                                                                               no_of_options, r, delta, sigma, t,\n",
    "                                                                               model_type, hidden_bias_init, hidden_weight_init, outer_bias_init)\n",
    "\n",
    "        positions = positions.reshape(no_of_options,1)\n",
    "        run_ind_arr = np.array(['Run' + str(run) for i in range(0, no_of_options)]).reshape(no_of_options,1)\n",
    "        df_nn_hedge_pv_instr_nos.loc[run, ['PV', 'NN RMSE', 'Calls Count', 'Puts Count', 'Fwds Count', 'Nulls Count']] = np.array(list(pvt0_nn) + list(np.array(nn_rmse).reshape(-1)) + instr_nos).reshape(1, 6)\n",
    "#         df_nn_hedge_params.loc[((run-1)*no_of_options + 1): ((run)*no_of_options), ['Runs', 'Positions', 'Strike', 'Pfl Wts', 'Deposit']] = np.transpose(np.array([run_ind_arr] + [positions] + params).reshape(no_of_options, 5))\n",
    "        df_nn_hedge_params.loc[((run-1)*no_of_options + 1): ((run)*no_of_options), ['Runs', 'Positions', 'Strike', 'Pfl Wts', 'Deposit']] = np.transpose(np.array([run_ind_arr] + [positions] + params).reshape(5, no_of_options))\n",
    "        df_nn_hedge_error.loc[:, run_ind_arr[0]] = nn_static_hedge_err.reshape(-1,1)\n",
    "    \n",
    "    return df_nn_hedge_pv_instr_nos, df_nn_hedge_params, df_nn_hedge_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/tljh/user/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/tljh/user/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/tljh/user/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/tljh/user/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/tljh/user/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/tljh/user/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/tljh/user/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/tljh/user/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/tljh/user/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/tljh/user/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n",
      "/opt/tljh/user/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_nn_hedge_pv_instr_nos, df_nn_hedge_params, df_nn_hedge_error = load_runs_to_df(df_sim_stocks, df_sim_stocks_test, df_bs_price, df_bs_price_test, \n",
    "                                                                                  no_of_options, r, delta, sigma, t,\n",
    "                                                                                  model_type, hidden_bias_init, hidden_weight_init, outer_bias_init,\n",
    "                                                                                  no_of_runs=no_of_runs)\n",
    "\n",
    "\n",
    "# df_nn_hedge_pv_instr_nos.to_csv('Stability Analysis - Outputs/Dataframes Optimized/df_nn_hedge_pv_instr_nos_' + file_ident + '_sim' + str(no_of_paths_test) + '_opt' + str(no_of_options) + '_runs' + str(no_of_runs) + '.csv')\n",
    "# df_nn_hedge_params.to_csv('Stability Analysis - Outputs/Dataframes Optimized/df_nn_hedge_params_' + file_ident + '_sim' + str(no_of_paths_test) + '_opt' + str(no_of_options) + '_runs' + str(no_of_runs) + '.csv')\n",
    "# df_nn_hedge_error.to_csv('Stability Analysis - Outputs/Dataframes Optimized/df_nn_hedge_error_' + file_ident + '_sim' + str(no_of_paths_test) + '_opt' + str(no_of_options) + '_runs' + str(no_of_runs) + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
