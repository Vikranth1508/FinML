{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/tljh/user/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import sobol_seq\n",
    "import numpy as np # linear algebra\n",
    "from numpy.linalg import multi_dot\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.optimizers as opt\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.constraints import Constraint\n",
    "from keras import backend as keras_backend\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "from numpy import savetxt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "\n",
    "num_cores = 32\n",
    "\n",
    "GPU = 1\n",
    "CPU = not GPU\n",
    "if GPU:\n",
    "    num_GPU = 1\n",
    "    num_CPU = 1\n",
    "if CPU:\n",
    "    num_CPU = 1\n",
    "    num_GPU = 0\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
    "session = tf.Session(config=config)\n",
    "keras_backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def generate_covariance_from_correlation(cor_mat, vol_list, dt):\n",
    "    vol_diag_mat = np.diag(vol_list)\n",
    "    cov_mat = np.dot(np.dot(vol_diag_mat,cor_mat),vol_diag_mat)*dt\n",
    "    return cov_mat\n",
    "\n",
    "def multi_variate_gbm_simulation(no_of_paths, no_of_exercise_days, no_of_assets, \n",
    "                                 curr_stock_price, r, vol_list, cov_mat, dt):\n",
    "    zero_mean = np.zeros(no_of_assets)\n",
    "    \n",
    "    #Antithetic variance reduction for monte-carlo\n",
    "    w_matx = np.random.multivariate_normal(zero_mean, cov_mat, (int(no_of_paths/2),no_of_exercise_days))\n",
    "    w_mat= np.concatenate((w_matx,- w_matx),axis=0)\n",
    "    w_mat = w_mat.reshape(no_of_paths, no_of_exercise_days)\n",
    "    \n",
    "    sim_ln_stock_mat = np.zeros((no_of_paths, no_of_exercise_days + 1))\n",
    "    sim_ln_stock_mat[:,0] = np.log(curr_stock_price)\n",
    "  \n",
    "    base_drift =  (r - 0.5 * np.square(vol_list[0])) * dt\n",
    "    \n",
    "    for day in range(1, no_of_exercise_days+1):\n",
    "        curr_drift = sim_ln_stock_mat[:,day-1] + base_drift\n",
    "        sim_ln_stock_mat[:,day] = curr_drift + w_mat[:,day-1]\n",
    "\n",
    "    sim_stock_mat = np.exp(sim_ln_stock_mat)\n",
    "    \n",
    "    return sim_stock_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Between(Constraint):\n",
    "    def __init__(self, min_value, max_value):\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "\n",
    "    def __call__(self, w):        \n",
    "        return keras_backend.clip(w, self.min_value, self.max_value)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'min_value': self.min_value,\n",
    "                'max_value': self.max_value}\n",
    "\n",
    "def pricer_down_out_barrier_by_nn(no_of_paths, no_of_barrier_points, sim_stock_mat, batch_size, no_of_epochs, no_of_hidden_nodes, no_of_output_nodes, t, nnet_model, min_mat, barrier):\n",
    "\n",
    "    continuation_value = np.ones((no_of_paths, 1))\n",
    "    option_value = np.zeros((no_of_paths, 1))\n",
    "    \n",
    "    #Finding intrinsic value of the option for all paths and exercise days\n",
    "    dt = t/no_of_barrier_points\n",
    "    es = EarlyStopping(monitor='loss', mode='min', patience=5) \n",
    "    continuation_value = np.maximum(sim_stock_mat[:,no_of_barrier_points] - k, 0)\n",
    "    \n",
    "    for day in range(no_of_barrier_points-1, -1, -1):\n",
    "        \n",
    "        stock_vec = sim_stock_mat[:,day+1]\n",
    "        \n",
    "        time_to_maturity = t - (t/no_of_barrier_points)\n",
    "        barrier_pricing = lambda s: discrete_barrier_down_price(s, k, r, vol_list[0], time_to_maturity, barrier, dt)\n",
    "        find_barrier_price = np.vectorize(barrier_pricing)\n",
    "        \n",
    "        continuation_value = find_barrier_price(stock_vec)\n",
    "        continuation_value = np.multiply(continuation_value, min_mat[:,day+1])         \n",
    "        option_value= np.maximum(continuation_value, 0)\n",
    "        \n",
    "        X_train = np.log(stock_vec)\n",
    "        X_train = X_train.reshape(-1,1)\n",
    "       \n",
    "        Y_train = option_value\n",
    "        Y_train = np.asarray(Y_train)\n",
    "        Y_train.reshape(-1,1,1)\n",
    "        \n",
    "        nnet_output = nnet_model.fit(X_train, Y_train , epochs=no_of_epochs, batch_size=batch_size, verbose=0,validation_split=0.3, callbacks=[es])            \n",
    "        w_vect = np.array(nnet_model.layers[0].get_weights()[0]).reshape(-1)\n",
    "        w_vect_2 = np.array(nnet_model.layers[1].get_weights()[0]).reshape(-1)\n",
    "        strikes = np.array(nnet_model.layers[0].get_weights()[1]).reshape(-1)\n",
    "        bias_2 = np.array(nnet_model.layers[1].get_weights()[1]).reshape(-1)\n",
    "        strikes = np.asarray(strikes)    \n",
    "        \n",
    "        stock_vec = sim_stock_mat[:,day]\n",
    "        vol = vol_list[0]\n",
    "        opt_val = np.zeros((no_of_paths, 1))\n",
    "        x = np.log(stock_vec)+((r-0.5* np.square(vol))*dt)\n",
    "        \n",
    "        no_of_options = np.sum((np.multiply(np.sign(w_vect), np.sign(strikes)))<0)\n",
    "        \n",
    "        for node in range(0,no_of_hidden_nodes):\n",
    "                w_o = w_vect[node]\n",
    "                mu = x*w_o+strikes[node]\n",
    "                var = (w_o*cov_mat[0]*w_o)\n",
    "                sd = var**0.5\n",
    "                ft = mu*(1-norm(0,sd).cdf(-mu))\n",
    "                st = (sd/(2*math.pi)**0.5)*np.exp(-0.5*(mu/sd)**2)\n",
    "                opt_val[:,0] = opt_val[:,0]+ w_vect_2[node]*(ft + st)\n",
    "        continuation_value = (opt_val[:,0]+bias_2)*np.exp(-r*dt)\n",
    "        \n",
    "    return(np.mean(continuation_value))\n",
    "\n",
    "def pricer_down_out_barrier_by_nn_pre(no_of_paths, no_of_barrier_points, sim_stock_mat, batch_size, no_of_epochs, no_of_hidden_nodes, no_of_output_nodes, t, nnet_model, min_mat):\n",
    "    \n",
    "    continuation_value = np.zeros((no_of_paths, 1))\n",
    "    \n",
    "    dt = t/no_of_barrier_points\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "    \n",
    "    for day in range(no_of_barrier_points-1,no_of_barrier_points-2, -1):\n",
    "                \n",
    "        stock_vec = sim_stock_mat[:,day+1]\n",
    "        \n",
    "        intrinsic_value = np.maximum(stock_vec - k, 0)\n",
    "        option_value = np.multiply(intrinsic_value, min_mat[:,day+1]) \n",
    "        \n",
    "        X_train = stock_vec\n",
    "        X_train = X_train.reshape(-1, 1)\n",
    "        \n",
    "        Y_train = option_value\n",
    "        Y_train = np.asarray(Y_train)\n",
    "        Y_train.reshape(-1,1,1)\n",
    "        \n",
    "        nnet_output = nnet_model.fit(X_train, Y_train , epochs=no_of_epochs, batch_size=batch_size, verbose=0, validation_split=0.3, callbacks=[es])\n",
    "\n",
    "    return nnet_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSM_call(s_t, k, r, vol, dt):\n",
    "    d_1_c = (1 / (vol * (dt ** 0.5))) \n",
    "    d1_log =  (np.log((s_t)/(k)) + ((r + (vol ** 2) / 2) * dt))\n",
    "    d_1 = d_1_c * d1_log\n",
    "    d_2 = d_1 - vol * (dt ** 0.5)\n",
    "    return (np.multiply(norm.cdf(d_1),  s_t) - (norm.cdf(d_2) * k * np.exp(-r * dt)))\n",
    "\n",
    "def continuous_barrier_down_out_call(s_t, k, r, vol, dt, B):\n",
    "    call_price = BSM_call(s_t, k, r, vol, dt)\n",
    "    new_s = (B**2) / s_t\n",
    "    adjusted_call =  BSM_call(new_s, k, r, vol, dt)\n",
    "    barrier_price = call_price - ((s_t/B)**(1 - 2*r/(vol**2))) * adjusted_call\n",
    "    return (barrier_price)                               \n",
    "                                  \n",
    "def discrete_barrier_down_price(s_t, k, r, vol, T_t, B, dt):\n",
    "    beta = 0.5826\n",
    "    discrete_correction = beta * vol * ((dt)**0.5)\n",
    "    corrected_barrier = B * np.exp(- discrete_correction)\n",
    "    return (continuous_barrier_down_out_call(s_t, k, r, vol, T_t, corrected_barrier)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Down and Out Barrier call option Pricing and Hedging\n",
    "# Comparison with Broadie and Glasserman Paper - results on 5 barrier points\n",
    "\n",
    "no_of_assets = 1\n",
    "cor_mat = [[1]]\n",
    "vol_list = np.array([0.3])\n",
    "curr_stock_price = 1*np.ones(no_of_assets)\n",
    "t = 0.2\n",
    "k = 1\n",
    "barrier_list = [0.85, 0.87, 0.89, 0.91, 0.93, 0.95, 0.97, 0.99]\n",
    "# barrier_list = [0.85]\n",
    "no_of_barrier_points = 5\n",
    "finer_path_multiplier = 1\n",
    "r = 0.1\n",
    "w = np.array([1])\n",
    "w = w.reshape(-1,1)\n",
    "no_of_paths =50000\n",
    "Notional = 100\n",
    "\n",
    "#Generate covariance matrix \n",
    "dt = t/no_of_barrier_points\n",
    "cov_mat = generate_covariance_from_correlation(cor_mat, vol_list, dt)\n",
    "\n",
    "#Generating stock prices for training neural network\n",
    "# sim_stock_mat = multi_variate_gbm_simulation(no_of_paths, no_of_barrier_points, no_of_assets, \n",
    "#                                                      curr_stock_price, r, vol_list, cov_mat, dt)\n",
    "# np.savetxt(\"Vikranth - Barrier Option Analysis\\np_sim_stocks.csv\", sim_stock_mat, delimiter=\",\")\n",
    "sim_stock_mat = np.genfromtxt(\"Vikranth - Barrier Option Analysis\\np_sim_stocks.csv\", delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nnet Initialisation\n",
    "batch_size = int(no_of_paths/10)\n",
    "no_of_epochs = 100\n",
    "no_of_hidden_nodes = 20\n",
    "no_of_output_nodes = 1\n",
    "\n",
    "#Learning starting weights\n",
    "nnet_model = Sequential()\n",
    "nnet_model.add(Dense(no_of_hidden_nodes, activation='relu',kernel_initializer = 'random_uniform'))\n",
    "nnet_model.add(Dense(1, activation='linear',kernel_initializer=keras.initializers.RandomUniform(minval=-0.01, maxval=0.01, seed=None)))\n",
    "nnet_model.compile(optimizer=opt.Adam(lr=1.5e-3), loss='mean_squared_error')\n",
    "\n",
    "# no_of_runs = 30\n",
    "no_of_runs = 1\n",
    "df_barrier_pv = pd.DataFrame(columns=['Barrier: ' + str(barrier) for barrier in barrier_list], \n",
    "                             index=[i for i in range(1, no_of_runs+1)])\n",
    "df_barrier_runtime = pd.DataFrame(columns=['Barrier: ' + str(barrier) for barrier in barrier_list], \n",
    "                             index=[i for i in range(1, no_of_runs+1)])\n",
    "\n",
    "for i in range(0, len(barrier_list)):\n",
    "    #Identifying region where stock prices hit the barrier\n",
    "    barrier = barrier_list[i]\n",
    "    I = (sim_stock_mat > barrier)\n",
    "    price_list=[]\n",
    "    run_time=[]\n",
    "    \n",
    "    for j in range(0, no_of_runs):\n",
    "        nnet_model = Sequential()\n",
    "        nnet_model.add(Dense(no_of_hidden_nodes, activation='relu',kernel_initializer = 'random_uniform'))\n",
    "        nnet_model.add(Dense(1, activation='linear',kernel_initializer=keras.initializers.RandomUniform(minval=-0.01, maxval=0.01, seed=None)))\n",
    "        nnet_model.compile(optimizer=opt.Adam(lr=1.5e-3), loss='mean_squared_error')\n",
    "        nnet_model = pricer_down_out_barrier_by_nn_pre(no_of_paths, no_of_barrier_points, sim_stock_mat, batch_size, no_of_epochs, no_of_hidden_nodes, no_of_output_nodes, t, nnet_model, I)\n",
    "    \n",
    "        #Training Neural Network for barrier pricing\n",
    "        no_of_epochs = 30\n",
    "        \n",
    "        start_time = time.time()\n",
    "        price = pricer_down_out_barrier_by_nn(no_of_paths, no_of_barrier_points, sim_stock_mat, batch_size, no_of_epochs, no_of_hidden_nodes, no_of_output_nodes, t, nnet_model, I, barrier)\n",
    "        elapsed_time_secs = time.time() - start_time\n",
    "        \n",
    "        price_list.append(price)\n",
    "        run_time.append(elapsed_time_secs)\n",
    "    \n",
    "#     df_barrier_pv.loc[:,['Barrier: ' + str(barrier)]] = np.array(price_list).reshape(-1,1)\n",
    "    df_barrier_runtime.loc[:,['Barrier: ' + str(barrier)]] = np.array(run_time).reshape(-1,1)\n",
    "     \n",
    "# df_barrier_pv.to_csv(\"df_barrier_pv.csv\")\n",
    "# df_barrier_runtime.to_csv(\"df_barrier_pv_run_time.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadie_glassermen_price = discrete_barrier_down_price(curr_stock_price, k, r, vol_list[0], t, barrier_list[-1], dt)\n",
    "print(broadie_glassermen_price*Notional)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
